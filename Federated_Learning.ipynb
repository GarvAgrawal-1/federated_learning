{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 2280,
          "sourceType": "datasetVersion",
          "datasetId": 1272
        },
        {
          "sourceId": 283795,
          "sourceType": "datasetVersion",
          "datasetId": 118250
        }
      ],
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'mnistasjpg:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F1272%2F2280%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240329%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240329T050440Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D38efd72341895ad50b6b50a0b50d9e43f224df705853b6fce221f0f9cf9b989576e1b59febeab60d57e18a28047201fb8cc5f4a89d4587cc5846b0328b8e5b0d2665ccb9b81bf714878c98f758374f0d7f0efd19a430ce92a75c08da0e3f2b5232eb58cc76fc4f1341608eaee4aa0076b512f035bbe1200558e6d9c1c84b250301b09bcb56f1ae3f0bc3202b8bab25935f83169caef5b4545f8a2326d8dfd1a2a5516ce41018b9d61b6ea2b110b09a4cd2f82d137c3eb674af37a3d8f4469b58a6b4a2ceb99050beffbb46bbf9306055aaf7211ace32124768ed998e730d60cc4d3d803efa834cd2325b214dcc540586ab36cb07b254bbdc6bba9ab07de779ab,cifar10-pngs-in-folders:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F118250%2F283795%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240329%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240329T050440Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D5e1ee42d2453eacdb4e718db1833fbc76251d324b8c0de9adb7ab5292ce540d2a542199f1ae7749fd1616b84096cc379d696a6d3f68ef9576ae750873019a1b45ab197a425f82f697ef00a91767f8323a0d09ba07e344fcb96af9d7c1cb70522df62bfc62484114bd388ac4cc8709661877ba31d19fb62f4308548252453f4f3ec9e48c4e1a1319e1c78ac0e790e9ccc7bb5b6a133ba7e4038bd5ae48186b0378d0614af2545825db4ba7d576eedbfb167b7875dcb72f2e22a50d444a8e21f8598019b82db5185d89d959f628a23a47a493d0303cfa8c64d3d3887aa8675121b97ef27529cf2938ca2f61637cfca6e2866ee3f822bfe8413b763abfae5260e48'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "A56_guq1mi8O",
        "outputId": "f97feeef-6f9e-4db6-d379-815785ea5d3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading mnistasjpg, 71746244 bytes compressed\n",
            "[==================================================] 71746244 bytes downloaded\n",
            "Downloaded and uncompressed: mnistasjpg\n",
            "Downloading cifar10-pngs-in-folders, 147219525 bytes compressed\n",
            "[==================================================] 147219525 bytes downloaded\n",
            "Downloaded and uncompressed: cifar10-pngs-in-folders\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import cv2\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import expand_dims\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, Input, Lambda\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras import backend as K"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-03-29T05:00:24.82263Z",
          "iopub.execute_input": "2024-03-29T05:00:24.823588Z",
          "iopub.status.idle": "2024-03-29T05:00:24.831435Z",
          "shell.execute_reply.started": "2024-03-29T05:00:24.823546Z",
          "shell.execute_reply": "2024-03-29T05:00:24.830229Z"
        },
        "trusted": true,
        "id": "g5777r9pmi8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imutils\n",
        "from imutils import paths"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T05:00:24.833345Z",
          "iopub.execute_input": "2024-03-29T05:00:24.834483Z",
          "iopub.status.idle": "2024-03-29T05:02:53.62981Z",
          "shell.execute_reply.started": "2024-03-29T05:00:24.834418Z",
          "shell.execute_reply": "2024-03-29T05:02:53.625907Z"
        },
        "trusted": true,
        "id": "J1BZfpUxmi8Y",
        "outputId": "0f7a7fc6-90fd-4898-ebdc-3ad64b7a75ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imutils in /usr/local/lib/python3.10/dist-packages (0.5.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Todo\n",
        "\n",
        "create subset of clients\n",
        "\n",
        "- increase comm rounds 300\n",
        "- increase hidden units 400\n",
        "- increase no of layers\n",
        "- no of clients 20"
      ],
      "metadata": {
        "id": "YT-VIkUrmi8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "debug = 0"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T05:03:05.526565Z",
          "iopub.execute_input": "2024-03-29T05:03:05.52694Z",
          "iopub.status.idle": "2024-03-29T05:03:05.532673Z",
          "shell.execute_reply.started": "2024-03-29T05:03:05.526913Z",
          "shell.execute_reply": "2024-03-29T05:03:05.531602Z"
        },
        "trusted": true,
        "id": "DYXaJxv7mi8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load(paths, verbose=-1):\n",
        "    '''expects images for each class in seperate dir,\n",
        "    e.g all digits in 0 class in the directory named 0 '''\n",
        "    data = list()\n",
        "    labels = list()\n",
        "    # loop over the input images\n",
        "    for (i, imgpath) in enumerate(paths):\n",
        "        # load the image and extract the class labels\n",
        "        im_gray = cv2.imread(imgpath , cv2.IMREAD_GRAYSCALE)\n",
        "        image = np.array(im_gray).flatten() # cv2.imread(imgpath)\n",
        "        # print(image.shape)\n",
        "        label = imgpath.split(os.path.sep)[-2]\n",
        "        # scale the image to [0, 1] and add to list\n",
        "        data.append(image/255)\n",
        "        labels.append(label)\n",
        "        # show an update every `verbose` images\n",
        "        if verbose > 0 and i > 0 and (i + 1) % verbose == 0:\n",
        "            print(\"[INFO] processed {}/{}\".format(i + 1, len(paths)))\n",
        "    # return a tuple of the data and labels\n",
        "\n",
        "    return data, labels\n",
        "\n",
        "def create_clients(image_list, label_list, num_clients=100, initial='clients'):\n",
        "    ''' return: a dictionary with keys clients' names and value as\n",
        "                data shards - tuple of images and label lists.\n",
        "        args:\n",
        "            image_list: a list of numpy arrays of training images\n",
        "            label_list:a list of binarized labels for each image\n",
        "            num_client: number of fedrated members (clients)\n",
        "            initials: the clients'name prefix, e.g, clients_1\n",
        "\n",
        "    '''\n",
        "\n",
        "    #create a list of client names\n",
        "    client_names = ['{}_{}'.format(initial, i+1) for i in range(num_clients)]\n",
        "\n",
        "    #randomize the data\n",
        "    data = list(zip(image_list, label_list))\n",
        "    random.shuffle(data)  # <- IID\n",
        "\n",
        "    # sort data for non-iid\n",
        "#     max_y = np.argmax(label_list, axis=-1)\n",
        "#     sorted_zip = sorted(zip(max_y, label_list, image_list), key=lambda x: x[0])\n",
        "#     data = [(x,y) for _,y,x in sorted_zip]\n",
        "\n",
        "    #shard data and place at each client\n",
        "    size = len(data)//num_clients\n",
        "    shards = [data[i:i + size] for i in range(0, size*num_clients, size)]\n",
        "\n",
        "    #number of clients must equal number of shards\n",
        "    assert(len(shards) == len(client_names))\n",
        "\n",
        "    return {client_names[i] : shards[i] for i in range(len(client_names))}\n",
        "\n",
        "\n",
        "def batch_data(data_shard, bs=32):\n",
        "    '''Takes in a clients data shard and create a tfds object off it\n",
        "    args:\n",
        "        shard: a data, label constituting a client's data shard\n",
        "        bs:batch size\n",
        "    return:\n",
        "        tfds object'''\n",
        "    #seperate shard into data and labels lists\n",
        "    data, label = zip(*data_shard)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((list(data), list(label)))\n",
        "    return dataset.shuffle(len(label)).batch(bs)\n",
        "\n",
        "\n",
        "def weight_scalling_factor(clients_trn_data, client_name):\n",
        "    client_names = list(clients_trn_data.keys())\n",
        "    #get the bs\n",
        "    bs = list(clients_trn_data[client_name])[0][0].shape[0]\n",
        "    #first calculate the total training data points across clinets\n",
        "    global_count = sum([tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy() for client_name in client_names])*bs\n",
        "    # get the total number of data points held by a client\n",
        "    local_count = tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy()*bs\n",
        "\n",
        "\n",
        "    if debug:\n",
        "        print('global_count', global_count, 'local_count', local_count, 'bs', bs)\n",
        "\n",
        "    return local_count/global_count\n",
        "\n",
        "\n",
        "def scale_model_weights(weight, scalar):\n",
        "    '''function for scaling a models weights'''\n",
        "    weight_final = []\n",
        "    steps = len(weight)\n",
        "    for i in range(steps):\n",
        "        weight_final.append(scalar * weight[i])\n",
        "    return weight_final\n",
        "\n",
        "\n",
        "\n",
        "def sum_scaled_weights(scaled_weight_list):\n",
        "    '''Return the sum of the listed scaled weights. The is equivalent to scaled avg of the weights'''\n",
        "    avg_grad = list()\n",
        "    #get the average grad accross all client gradients\n",
        "    for grad_list_tuple in zip(*scaled_weight_list):\n",
        "        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)\n",
        "        avg_grad.append(layer_mean)\n",
        "\n",
        "    return avg_grad\n",
        "\n",
        "\n",
        "def test_model(X_test, Y_test,  model, comm_round):\n",
        "    cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "    #logits = model.predict(X_test, batch_size=100)\n",
        "    logits = model.predict(X_test)\n",
        "    loss = cce(Y_test, logits)\n",
        "    acc = accuracy_score(tf.argmax(logits, axis=1), tf.argmax(Y_test, axis=1))\n",
        "    print('comm_round: {} | global_acc: {:.3%} | global_loss: {}'.format(comm_round, acc, loss))\n",
        "    return acc, loss\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T05:03:14.790496Z",
          "iopub.execute_input": "2024-03-29T05:03:14.791041Z",
          "iopub.status.idle": "2024-03-29T05:03:14.807123Z",
          "shell.execute_reply.started": "2024-03-29T05:03:14.791012Z",
          "shell.execute_reply": "2024-03-29T05:03:14.805443Z"
        },
        "trusted": true,
        "id": "-28TvjYbmi8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleMLP:\n",
        "    @staticmethod\n",
        "    def build(shape, classes):\n",
        "        model = Sequential()\n",
        "        model.add(Dense(200, input_shape=(shape,)))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(Dense(200))\n",
        "        model.add(Activation(\"relu\"))\n",
        "        model.add(Dense(classes))\n",
        "        model.add(Activation(\"softmax\"))\n",
        "        return model\n",
        "\n",
        "#     def build(shape, classes):\n",
        "#         model = Sequential()\n",
        "#         model.add(Input(shape=(shape[0], shape[1], shape[2])))\n",
        "#         #model.add(Lambda(lambda x: expand_dims(x, axis=-1)))\n",
        "#         model.add(Conv2D(filters=64, kernel_size=3, padding=\"same\"))\n",
        "#         model.add(Activation(\"relu\"))\n",
        "#         model.add(Conv2D(filters=64, kernel_size=3, padding=\"same\"))\n",
        "#         model.add(Activation(\"relu\"))\n",
        "#         model.add(MaxPooling2D())\n",
        "#         model.add(Conv2D(filters=128, kernel_size=3, padding=\"same\"))\n",
        "#         model.add(Activation(\"relu\"))\n",
        "#         model.add(Conv2D(filters=128, kernel_size=3, padding=\"same\"))\n",
        "#         model.add(Activation(\"relu\"))\n",
        "#         model.add(MaxPooling2D())\n",
        "#         model.add(Activation(\"relu\"))\n",
        "#         model.add(Conv2D(filters=256, kernel_size=3, padding=\"same\"))\n",
        "#         model.add(Activation(\"relu\"))\n",
        "#         model.add(Conv2D(filters=256, kernel_size=3, padding=\"same\"))\n",
        "#         model.add(Activation(\"relu\"))\n",
        "#         model.add(MaxPooling2D())\n",
        "#         model.add(Activation(\"relu\"))\n",
        "#         model.add(Conv2D(filters=512, kernel_size=3, padding=\"same\"))\n",
        "#         model.add(Activation(\"relu\"))\n",
        "#         model.add(Conv2D(filters=512, kernel_size=3, padding=\"same\"))\n",
        "#         model.add(Activation(\"relu\"))\n",
        "#         model.add(MaxPooling2D())\n",
        "#         model.add(Flatten())\n",
        "#         model.add(Dense(32))\n",
        "#         model.add(Dense(classes))\n",
        "#         model.add(Activation(\"softmax\"))\n",
        "#         return model"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T05:03:32.865568Z",
          "iopub.execute_input": "2024-03-29T05:03:32.865938Z",
          "iopub.status.idle": "2024-03-29T05:03:32.872971Z",
          "shell.execute_reply.started": "2024-03-29T05:03:32.865911Z",
          "shell.execute_reply": "2024-03-29T05:03:32.871741Z"
        },
        "trusted": true,
        "id": "d3OgPA6Vmi8f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#declear path to your mnist data folder\n",
        "img_path = '../input/mnistasjpg/trainingSet/trainingSet' #'../input/cifar10-pngs-in-folders/cifar10/test'  # <-- test dataset #'../input/mnistasjpg/trainingSample/trainingSample' # <-- smaller dataset\n",
        "\n",
        "#get the path list using the path object\n",
        "image_paths = list(paths.list_images(img_path))\n",
        "\n",
        "#apply our function\n",
        "image_list, label_list = load(image_paths, verbose=10000)\n",
        "\n",
        "#binarize the labels\n",
        "lb = LabelBinarizer()\n",
        "label_list = lb.fit_transform(label_list)"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2024-03-29T05:03:39.362298Z",
          "iopub.execute_input": "2024-03-29T05:03:39.362681Z",
          "iopub.status.idle": "2024-03-29T05:03:39.399225Z",
          "shell.execute_reply.started": "2024-03-29T05:03:39.362651Z",
          "shell.execute_reply": "2024-03-29T05:03:39.397439Z"
        },
        "trusted": true,
        "id": "Zhb0DY6Cmi8g",
        "outputId": "33fd8d71-3882-4ce2-bad3-527d4e6dad6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] processed 10000/42000\n",
            "[INFO] processed 20000/42000\n",
            "[INFO] processed 30000/42000\n",
            "[INFO] processed 40000/42000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#split data into training and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(image_list,\n",
        "                                                    label_list,\n",
        "                                                    test_size=0.1,\n",
        "                                                    random_state=42)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T05:02:53.637805Z",
          "iopub.status.idle": "2024-03-29T05:02:53.638198Z",
          "shell.execute_reply.started": "2024-03-29T05:02:53.638008Z",
          "shell.execute_reply": "2024-03-29T05:02:53.638024Z"
        },
        "trusted": true,
        "id": "JLrfMx-8mi8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### IID"
      ],
      "metadata": {
        "id": "xwCue_UOmi8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train), len(X_test), len(y_train), len(y_test)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T05:02:53.639196Z",
          "iopub.status.idle": "2024-03-29T05:02:53.639478Z",
          "shell.execute_reply.started": "2024-03-29T05:02:53.639332Z",
          "shell.execute_reply": "2024-03-29T05:02:53.639344Z"
        },
        "trusted": true,
        "id": "gtJ65Xjbmi8i",
        "outputId": "19166a4f-ae0e-424b-b4b0-064f6021ee4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(37800, 4200, 37800, 4200)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create clients\n",
        "clients = create_clients(X_train, y_train, num_clients=100, initial='client')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T05:02:53.64292Z",
          "iopub.status.idle": "2024-03-29T05:02:53.643289Z",
          "shell.execute_reply.started": "2024-03-29T05:02:53.643125Z",
          "shell.execute_reply": "2024-03-29T05:02:53.643139Z"
        },
        "trusted": true,
        "id": "CRx02Y7Hmi8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# client_names = ['{}_{}'.format('client', i+1) for i in range(100)]\n",
        "# s = clients['client_1'][0][1]*0\n",
        "# for c in client_names:\n",
        "#     sum = clients[c][0][1]\n",
        "#     for i in range(1,378):\n",
        "#         sum = sum + clients[c][i][1]\n",
        "\n",
        "#     s = s + sum/378\n",
        "# s"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T05:02:53.644261Z",
          "iopub.status.idle": "2024-03-29T05:02:53.644562Z",
          "shell.execute_reply.started": "2024-03-29T05:02:53.644418Z",
          "shell.execute_reply": "2024-03-29T05:02:53.644431Z"
        },
        "trusted": true,
        "id": "45t5ZzRLmi8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#process and batch the training data for each client\n",
        "clients_batched = dict()\n",
        "for (client_name, data) in clients.items():\n",
        "    clients_batched[client_name] = batch_data(data)\n",
        "\n",
        "#process and batch the test set\n",
        "test_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T05:02:53.645338Z",
          "iopub.status.idle": "2024-03-29T05:02:53.645613Z",
          "shell.execute_reply.started": "2024-03-29T05:02:53.645481Z",
          "shell.execute_reply": "2024-03-29T05:02:53.645493Z"
        },
        "trusted": true,
        "id": "7PasTSY6mi8j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.01\n",
        "comms_round = 300\n",
        "loss='categorical_crossentropy'\n",
        "metrics = ['accuracy']\n",
        "optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=lr,\n",
        "                decay=lr / comms_round,\n",
        "                momentum=0.9\n",
        "               )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T05:02:53.646181Z",
          "iopub.status.idle": "2024-03-29T05:02:53.646433Z",
          "shell.execute_reply.started": "2024-03-29T05:02:53.646308Z",
          "shell.execute_reply": "2024-03-29T05:02:53.646319Z"
        },
        "trusted": true,
        "id": "kXmDu6Pbmi8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize global model\n",
        "\n",
        "build_shape = 784 #(28, 28, 3)  # 1024 <- CIFAR-10    # 784 # for MNIST\n",
        "\n",
        "smlp_global = SimpleMLP()\n",
        "global_model = smlp_global.build(build_shape, 10)\n",
        "global_acc_list = []\n",
        "global_loss_list = []"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T05:02:53.647498Z",
          "iopub.status.idle": "2024-03-29T05:02:53.647989Z",
          "shell.execute_reply.started": "2024-03-29T05:02:53.647776Z",
          "shell.execute_reply": "2024-03-29T05:02:53.647797Z"
        },
        "trusted": true,
        "id": "rccGX93Umi8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#commence global training loop\n",
        "for comm_round in range(comms_round):\n",
        "\n",
        "    # get the global model's weights - will serve as the initial weights for all local models\n",
        "    global_weights = global_model.get_weights()\n",
        "\n",
        "    #initial list to collect local model weights after scalling\n",
        "    scaled_local_weight_list = list()\n",
        "\n",
        "    #randomize client data - using keys\n",
        "    all_client_names = list(clients_batched.keys())\n",
        "\n",
        "    client_names = random.sample(all_client_names, k=10)\n",
        "    # print(client_names, len(client_names))\n",
        "    random.shuffle(client_names)\n",
        "\n",
        "#     if debug:\n",
        "#         # print('all_client_names', all_client_names)\n",
        "#         print('client_names', client_names, len(client_names))\n",
        "\n",
        "\n",
        "    #loop through each client and create new local model\n",
        "    for client in client_names:\n",
        "        smlp_local = SimpleMLP()\n",
        "        local_model = smlp_local.build(build_shape, 10)\n",
        "        local_model.compile(loss=loss,\n",
        "                      optimizer=optimizer,\n",
        "                      metrics=metrics)\n",
        "\n",
        "        #set local model weight to the weight of the global model\n",
        "        local_model.set_weights(global_weights)\n",
        "\n",
        "        #fit local model with client's data\n",
        "        local_model.fit(clients_batched[client], epochs=1, verbose=0)\n",
        "\n",
        "        #scale the model weights and add to list\n",
        "        scaling_factor = 0.1 # weight_scalling_factor(clients_batched, client)\n",
        "        # print('scaling_factor', scaling_factor)\n",
        "        scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
        "        scaled_local_weight_list.append(scaled_weights)\n",
        "\n",
        "        #clear session to free memory after each communication round\n",
        "        K.clear_session()\n",
        "\n",
        "    #to get the average over all the local model, we simply take the sum of the scaled weights\n",
        "    average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
        "\n",
        "    #update global model\n",
        "    global_model.set_weights(average_weights)\n",
        "\n",
        "    #test global model and print out metrics after each communications round\n",
        "    for(X_test, Y_test) in test_batched:\n",
        "        global_acc, global_loss = test_model(X_test, Y_test, global_model, comm_round)\n",
        "        global_acc_list.append(global_acc)\n",
        "        global_loss_list.append(global_loss)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T05:02:53.652125Z",
          "iopub.status.idle": "2024-03-29T05:02:53.652719Z",
          "shell.execute_reply.started": "2024-03-29T05:02:53.652427Z",
          "shell.execute_reply": "2024-03-29T05:02:53.652451Z"
        },
        "trusted": true,
        "id": "Axjtypkkmi8k",
        "outputId": "0e7bf7d3-ceaf-4f70-b1a6-3aca79c6362c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "132/132 [==============================] - 1s 4ms/step\n",
            "comm_round: 0 | global_acc: 41.476% | global_loss: 2.272965908050537\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 1 | global_acc: 61.857% | global_loss: 2.2244744300842285\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 2 | global_acc: 71.595% | global_loss: 2.158291816711426\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 3 | global_acc: 75.643% | global_loss: 2.069295883178711\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 4 | global_acc: 78.643% | global_loss: 1.9829764366149902\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 5 | global_acc: 81.786% | global_loss: 1.9182661771774292\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 6 | global_acc: 82.571% | global_loss: 1.864935040473938\n",
            "132/132 [==============================] - 0s 3ms/step\n",
            "comm_round: 7 | global_acc: 84.262% | global_loss: 1.824173927307129\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 8 | global_acc: 85.381% | global_loss: 1.7929739952087402\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 9 | global_acc: 85.762% | global_loss: 1.7668883800506592\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 10 | global_acc: 86.500% | global_loss: 1.7474688291549683\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 11 | global_acc: 86.952% | global_loss: 1.7329684495925903\n",
            "132/132 [==============================] - 0s 3ms/step\n",
            "comm_round: 12 | global_acc: 87.214% | global_loss: 1.7210770845413208\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 13 | global_acc: 87.119% | global_loss: 1.706674337387085\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 14 | global_acc: 87.929% | global_loss: 1.69942307472229\n",
            "132/132 [==============================] - 0s 3ms/step\n",
            "comm_round: 15 | global_acc: 88.214% | global_loss: 1.6899389028549194\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 16 | global_acc: 88.238% | global_loss: 1.6836678981781006\n",
            "132/132 [==============================] - 0s 3ms/step\n",
            "comm_round: 17 | global_acc: 88.262% | global_loss: 1.676629900932312\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 18 | global_acc: 88.524% | global_loss: 1.6709800958633423\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 19 | global_acc: 88.905% | global_loss: 1.6631942987442017\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 20 | global_acc: 89.238% | global_loss: 1.6585040092468262\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 21 | global_acc: 89.095% | global_loss: 1.655791997909546\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 22 | global_acc: 89.190% | global_loss: 1.6542558670043945\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 23 | global_acc: 89.333% | global_loss: 1.649196743965149\n",
            "132/132 [==============================] - 0s 3ms/step\n",
            "comm_round: 24 | global_acc: 89.357% | global_loss: 1.645529866218567\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 25 | global_acc: 89.976% | global_loss: 1.6423895359039307\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 26 | global_acc: 90.190% | global_loss: 1.6383168697357178\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 27 | global_acc: 90.000% | global_loss: 1.6362148523330688\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 28 | global_acc: 89.667% | global_loss: 1.635133147239685\n",
            "132/132 [==============================] - 0s 3ms/step\n",
            "comm_round: 29 | global_acc: 90.214% | global_loss: 1.6314564943313599\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 30 | global_acc: 89.786% | global_loss: 1.6318540573120117\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 31 | global_acc: 90.238% | global_loss: 1.6269112825393677\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 32 | global_acc: 90.619% | global_loss: 1.6244587898254395\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 33 | global_acc: 90.167% | global_loss: 1.6255394220352173\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 34 | global_acc: 90.429% | global_loss: 1.6218090057373047\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 35 | global_acc: 90.619% | global_loss: 1.6211704015731812\n",
            "132/132 [==============================] - 0s 3ms/step\n",
            "comm_round: 36 | global_acc: 90.786% | global_loss: 1.6173460483551025\n",
            "132/132 [==============================] - 0s 3ms/step\n",
            "comm_round: 37 | global_acc: 90.762% | global_loss: 1.617231011390686\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 38 | global_acc: 90.952% | global_loss: 1.616281509399414\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 39 | global_acc: 90.976% | global_loss: 1.614853024482727\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 40 | global_acc: 90.857% | global_loss: 1.6130385398864746\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 41 | global_acc: 91.190% | global_loss: 1.6126410961151123\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 42 | global_acc: 91.024% | global_loss: 1.6091707944869995\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 43 | global_acc: 91.167% | global_loss: 1.6088169813156128\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 44 | global_acc: 90.976% | global_loss: 1.6092270612716675\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 45 | global_acc: 91.214% | global_loss: 1.6068521738052368\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 46 | global_acc: 91.381% | global_loss: 1.6071354150772095\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 47 | global_acc: 91.214% | global_loss: 1.6065946817398071\n",
            "132/132 [==============================] - 0s 3ms/step\n",
            "comm_round: 48 | global_acc: 91.500% | global_loss: 1.6042555570602417\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 49 | global_acc: 91.500% | global_loss: 1.6026432514190674\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 50 | global_acc: 91.452% | global_loss: 1.6039067506790161\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 51 | global_acc: 91.548% | global_loss: 1.6019514799118042\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 52 | global_acc: 91.524% | global_loss: 1.6020863056182861\n",
            "132/132 [==============================] - 0s 3ms/step\n",
            "comm_round: 53 | global_acc: 91.548% | global_loss: 1.5985691547393799\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 54 | global_acc: 91.619% | global_loss: 1.5982978343963623\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 55 | global_acc: 91.833% | global_loss: 1.5976871252059937\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 56 | global_acc: 91.833% | global_loss: 1.5962647199630737\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 57 | global_acc: 91.810% | global_loss: 1.5965063571929932\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 58 | global_acc: 91.833% | global_loss: 1.5956699848175049\n",
            "132/132 [==============================] - 0s 3ms/step\n",
            "comm_round: 59 | global_acc: 91.690% | global_loss: 1.5943491458892822\n",
            "132/132 [==============================] - 0s 3ms/step\n",
            "comm_round: 60 | global_acc: 91.905% | global_loss: 1.5930219888687134\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 61 | global_acc: 91.881% | global_loss: 1.5946451425552368\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 62 | global_acc: 92.024% | global_loss: 1.5927554368972778\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 63 | global_acc: 91.976% | global_loss: 1.5916427373886108\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 64 | global_acc: 92.262% | global_loss: 1.590339183807373\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 65 | global_acc: 92.048% | global_loss: 1.5918835401535034\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 66 | global_acc: 92.238% | global_loss: 1.589257001876831\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 67 | global_acc: 92.357% | global_loss: 1.5892224311828613\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 68 | global_acc: 92.333% | global_loss: 1.5869752168655396\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 69 | global_acc: 92.333% | global_loss: 1.5878360271453857\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 70 | global_acc: 92.333% | global_loss: 1.5863984823226929\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 71 | global_acc: 92.214% | global_loss: 1.5873998403549194\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 72 | global_acc: 92.405% | global_loss: 1.585180640220642\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 73 | global_acc: 92.214% | global_loss: 1.5849318504333496\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 74 | global_acc: 92.786% | global_loss: 1.5844770669937134\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 75 | global_acc: 92.405% | global_loss: 1.5836176872253418\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 76 | global_acc: 92.619% | global_loss: 1.583045244216919\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 77 | global_acc: 92.762% | global_loss: 1.5818835496902466\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 78 | global_acc: 92.476% | global_loss: 1.5819896459579468\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 79 | global_acc: 92.548% | global_loss: 1.5819591283798218\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 80 | global_acc: 92.667% | global_loss: 1.581263780593872\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 81 | global_acc: 92.452% | global_loss: 1.5813374519348145\n",
            "132/132 [==============================] - 0s 3ms/step\n",
            "comm_round: 82 | global_acc: 92.571% | global_loss: 1.580700159072876\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 83 | global_acc: 92.595% | global_loss: 1.5800343751907349\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 84 | global_acc: 93.048% | global_loss: 1.5786741971969604\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 85 | global_acc: 92.500% | global_loss: 1.5813195705413818\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 86 | global_acc: 92.857% | global_loss: 1.579921841621399\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 87 | global_acc: 93.048% | global_loss: 1.5780799388885498\n",
            "132/132 [==============================] - 0s 2ms/step\n",
            "comm_round: 88 | global_acc: 92.857% | global_loss: 1.5791223049163818\n",
            "  1/132 [..............................] - ETA: 4s"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IID\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(16,4))\n",
        "plt.subplot(121)\n",
        "plt.plot(list(range(0,len(global_loss_list))), global_loss_list)\n",
        "plt.subplot(122)\n",
        "plt.plot(list(range(0,len(global_acc_list))), global_acc_list)\n",
        "print('IID | total comm rounds', len(global_acc_list))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T05:02:53.654417Z",
          "iopub.status.idle": "2024-03-29T05:02:53.654923Z",
          "shell.execute_reply.started": "2024-03-29T05:02:53.654668Z",
          "shell.execute_reply": "2024-03-29T05:02:53.654706Z"
        },
        "trusted": true,
        "id": "lsLTIxXqmi8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iid_df = pd.DataFrame(list(zip(global_acc_list, global_loss_list)), columns =['global_acc_list', 'global_loss_list'])\n",
        "iid_df.to_csv('MNIST_IID.csv',index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T05:02:53.656827Z",
          "iopub.status.idle": "2024-03-29T05:02:53.657311Z",
          "shell.execute_reply.started": "2024-03-29T05:02:53.657075Z",
          "shell.execute_reply": "2024-03-29T05:02:53.657095Z"
        },
        "trusted": true,
        "id": "dfbpWQkimi8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Non-IID"
      ],
      "metadata": {
        "id": "GdgolloHmi8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_clients(image_list, label_list, num_clients=100, initial='clients'):\n",
        "    ''' return: a dictionary with keys clients' names and value as\n",
        "                data shards - tuple of images and label lists.\n",
        "        args:\n",
        "            image_list: a list of numpy arrays of training images\n",
        "            label_list:a list of binarized labels for each image\n",
        "            num_client: number of fedrated members (clients)\n",
        "            initials: the clients'name prefix, e.g, clients_1\n",
        "\n",
        "    '''\n",
        "\n",
        "    #create a list of client names\n",
        "    client_names = ['{}_{}'.format(initial, i+1) for i in range(num_clients)]\n",
        "\n",
        "    #randomize the data\n",
        "    # data = list(zip(image_list, label_list))\n",
        "    # random.shuffle(data)  # <- IID\n",
        "\n",
        "    # sort data for non-iid\n",
        "    max_y = np.argmax(label_list, axis=-1)\n",
        "    sorted_zip = sorted(zip(max_y, label_list, image_list), key=lambda x: x[0])\n",
        "    data = [(x,y) for _,y,x in sorted_zip]\n",
        "\n",
        "    #shard data and place at each client\n",
        "    size = len(data)//num_clients\n",
        "    shards = [data[i:i + size] for i in range(0, size*num_clients, size)]\n",
        "\n",
        "    #number of clients must equal number of shards\n",
        "    assert(len(shards) == len(client_names))\n",
        "\n",
        "    return {client_names[i] : shards[i] for i in range(len(client_names))}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T05:02:53.658675Z",
          "iopub.status.idle": "2024-03-29T05:02:53.659128Z",
          "shell.execute_reply.started": "2024-03-29T05:02:53.658909Z",
          "shell.execute_reply": "2024-03-29T05:02:53.658927Z"
        },
        "trusted": true,
        "id": "EjzNONPrmi8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YbNJUDzCmi8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train), len(X_test), len(y_train), len(y_test)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T05:02:53.661133Z",
          "iopub.status.idle": "2024-03-29T05:02:53.661587Z",
          "shell.execute_reply.started": "2024-03-29T05:02:53.661356Z",
          "shell.execute_reply": "2024-03-29T05:02:53.661375Z"
        },
        "trusted": true,
        "id": "G_H5YuHAmi8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create clients\n",
        "clients = create_clients(X_train, y_train, num_clients=100, initial='client')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T05:02:53.662644Z",
          "iopub.status.idle": "2024-03-29T05:02:53.663112Z",
          "shell.execute_reply.started": "2024-03-29T05:02:53.662888Z",
          "shell.execute_reply": "2024-03-29T05:02:53.662906Z"
        },
        "trusted": true,
        "id": "6wTO4zb0mi8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#process and batch the training data for each client\n",
        "clients_batched = dict()\n",
        "for (client_name, data) in clients.items():\n",
        "    clients_batched[client_name] = batch_data(data)\n",
        "\n",
        "#process and batch the test set\n",
        "test_batched = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(len(y_test))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T05:02:53.664778Z",
          "iopub.status.idle": "2024-03-29T05:02:53.665195Z",
          "shell.execute_reply.started": "2024-03-29T05:02:53.664986Z",
          "shell.execute_reply": "2024-03-29T05:02:53.665013Z"
        },
        "trusted": true,
        "id": "DLOIIg_Gmi8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.01\n",
        "comms_round = 300\n",
        "loss='categorical_crossentropy'\n",
        "metrics = ['accuracy']\n",
        "optimizer = SGD(lr=lr,\n",
        "                decay=lr / comms_round,\n",
        "                momentum=0.9\n",
        "               )"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T05:02:53.667133Z",
          "iopub.status.idle": "2024-03-29T05:02:53.667587Z",
          "shell.execute_reply.started": "2024-03-29T05:02:53.667342Z",
          "shell.execute_reply": "2024-03-29T05:02:53.66736Z"
        },
        "trusted": true,
        "id": "HTlQeRg1mi8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize global model\n",
        "\n",
        "build_shape = 784 #(32, 32, 3)  # 1024 <- CIFAR-10    # 784 # for MNIST\n",
        "\n",
        "smlp_global = SimpleMLP()\n",
        "global_model = smlp_global.build(build_shape, 10)\n",
        "global_acc_list = []\n",
        "global_loss_list = []"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T05:02:53.668954Z",
          "iopub.status.idle": "2024-03-29T05:02:53.669397Z",
          "shell.execute_reply.started": "2024-03-29T05:02:53.669174Z",
          "shell.execute_reply": "2024-03-29T05:02:53.669193Z"
        },
        "trusted": true,
        "id": "DV6zULaNmi8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#commence global training loop\n",
        "for comm_round in range(comms_round):\n",
        "\n",
        "    # get the global model's weights - will serve as the initial weights for all local models\n",
        "    global_weights = global_model.get_weights()\n",
        "\n",
        "    #initial list to collect local model weights after scalling\n",
        "    scaled_local_weight_list = list()\n",
        "\n",
        "    #randomize client data - using keys\n",
        "    all_client_names = list(clients_batched.keys())\n",
        "\n",
        "    client_names = random.sample(all_client_names, k=10)\n",
        "    random.shuffle(client_names)\n",
        "    if debug:\n",
        "        # print('all_client_names', all_client_names)\n",
        "        print('client_names', client_names)\n",
        "\n",
        "    #loop through each client and create new local model\n",
        "    for client in client_names:\n",
        "        smlp_local = SimpleMLP()\n",
        "        local_model = smlp_local.build(build_shape, 10)\n",
        "        local_model.compile(loss=loss,\n",
        "                      optimizer=optimizer,\n",
        "                      metrics=metrics)\n",
        "\n",
        "        #set local model weight to the weight of the global model\n",
        "        local_model.set_weights(global_weights)\n",
        "\n",
        "        #fit local model with client's data\n",
        "        local_model.fit(clients_batched[client], epochs=1, verbose=0)\n",
        "\n",
        "        #scale the model weights and add to list\n",
        "        scaling_factor = 0.1 # weight_scalling_factor(clients_batched, client)\n",
        "        scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
        "        scaled_local_weight_list.append(scaled_weights)\n",
        "\n",
        "        #clear session to free memory after each communication round\n",
        "        K.clear_session()\n",
        "\n",
        "    #to get the average over all the local model, we simply take the sum of the scaled weights\n",
        "    average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
        "\n",
        "    #update global model\n",
        "    global_model.set_weights(average_weights)\n",
        "\n",
        "    #test global model and print out metrics after each communications round\n",
        "    for(X_test, Y_test) in test_batched:\n",
        "        global_acc, global_loss = test_model(X_test, Y_test, global_model, comm_round)\n",
        "        global_acc_list.append(global_acc)\n",
        "        global_loss_list.append(global_loss)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T05:02:53.671092Z",
          "iopub.status.idle": "2024-03-29T05:02:53.67151Z",
          "shell.execute_reply.started": "2024-03-29T05:02:53.671297Z",
          "shell.execute_reply": "2024-03-29T05:02:53.671314Z"
        },
        "trusted": true,
        "id": "mTGCGT8Pmi8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Non-IID\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(16,4))\n",
        "plt.subplot(121)\n",
        "plt.plot(list(range(0,len(global_loss_list))), global_loss_list)\n",
        "plt.subplot(122)\n",
        "plt.plot(list(range(0,len(global_acc_list))), global_acc_list)\n",
        "print('Non-IID | total comm rounds', len(global_acc_list))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T05:02:53.673112Z",
          "iopub.status.idle": "2024-03-29T05:02:53.673547Z",
          "shell.execute_reply.started": "2024-03-29T05:02:53.673325Z",
          "shell.execute_reply": "2024-03-29T05:02:53.673344Z"
        },
        "trusted": true,
        "id": "3gKQRgmfmi8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "noniid_df = pd.DataFrame(list(zip(global_acc_list, global_loss_list)), columns =['global_acc_list', 'global_loss_list'])\n",
        "noniid_df.to_csv('CIFAR-10_Non-IID.csv',index=False)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T05:02:53.67513Z",
          "iopub.status.idle": "2024-03-29T05:02:53.675556Z",
          "shell.execute_reply.started": "2024-03-29T05:02:53.675352Z",
          "shell.execute_reply": "2024-03-29T05:02:53.675369Z"
        },
        "trusted": true,
        "id": "-PrJRn7vmi8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-29T05:02:53.676902Z",
          "iopub.status.idle": "2024-03-29T05:02:53.67733Z",
          "shell.execute_reply.started": "2024-03-29T05:02:53.677114Z",
          "shell.execute_reply": "2024-03-29T05:02:53.677132Z"
        },
        "trusted": true,
        "id": "TY1VHbyOmi8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3lGLgBSHmi8p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}